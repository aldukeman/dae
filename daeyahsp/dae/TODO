
TODO

CODE

* implement two IQR/median statistics:
    * for feasible fitness
    * for unfeaible fitness

* multi-core implementation by Caner Candan
    * first in DAE
    * if it works in PEO
* fix the max of nodes numbers during the init around the quantile next to the max best quantile of all instances
* choose a sub-set of instances
    * in 24h, Matthias says we can do a parameter setting for ~5 instances
* get the sub-set of all the parameters that have an impact on the results
* use an eoBinOp instead of the eoQuadOp for the crossover?
    * beware that to get the original behaviour one should do an explicit copy of the oher individual 
        * this introduce a new parameter: the probability to put the copy

* supprimer les goals qui ne sont pas nécéssaires :
    * goals intermédiaires triviaux (sous-plan vide)
    * cycles triviaux (goal dans un état, puis autres goals, puis retour sur goal précédent => on peut supprimer les intermédiaires)

* choisir le radius en fonction du nombre de date possibles (par exemple 20%)
* dans l'init, autoriser des décompositions vides
    * au moins un à l'init?
    * en considérant qu'il sera gardé ou viré par la sélection
* séparer random_atom_change et random_atom_add (dans addatom) et les mettre dans deux opérateurs différents
* dans addgoal et crossover: découper avant le sous-plan qui a nécéssité le plus de noeuds lors de l'évaluation, penser à garder l'aspect aléatoire
* nécéssiterait de sauver les étapes de résolutions intermédiaires : fitness en plusieurs parties (une pour chaque goal)
    * permettrait d'améliorer grandement la rapidité d'évaluation
    * éventuellement, voir si on peut modifier les opérateurs de variations qui ne modifient pas la décomposition avant un sous-plan qui a été difficile à trouver
    * éventuellement, maintenir un tableau associatif des couples (<état initial,état final>=>sous-plan) pour éviter de recalculer des sous-plans déjà calculés à d'autres moments
    * mémoriser la graine aléatoire utilisée par yahsp, pour garantir le meme comportement entre deux évaluations
* s'il apparait des pb de mémoire, penser que yahsp garde en mémoire la liste complète des tous les états qu'il a rencontré. On peut supprimer cette structure si nécéssaire sans réduire l'efficacité de yahsp.


EXPERIMENTS

* do a parameter setting on the quantile for the estimation of b_max with a max b_max of 10000
* check distribution of used nodes number versus iterations and position in the decomposition
* check the entropy of sort of the decompositions versus iterations
* check existence duration of a given decomposition
* check distribution of mutexes atoms
* check correlation of last_reached versus iterations
* check if there is a diversity loss during iterations,
    * and correlations with fitness, plan structure and decomposition structure
        * necessitate to know how to quantify those structures
        * and/or distances

* regarder avec yahsp la distribution de la longueur des plans
* décider entre le cross-over aveugle ou le cross-over qui trie les dates
* remplacer b_max par un temps CPU limite?
* faire des tests pour vérifier si on autorise des individus sans decomposition (daex_init.h:45)
    * laisser faire le hasard?
    * inclure au moins un seul à l'init?
* dans addAtom, voir s'il ne faudrait pas relacher la contrainte d'égalité de date entre le nouvel atome choisi et la date du goal, peut-etre un <= serait plus approprié, vu que les dates des goal ne sont pas forcément ordonnées, ou alors avec un radius autour de la date du goal ?

----------------------------------

MAYBE TO BE DONE

* n'utiliser l_max qu'à l'init, et ne pas l'utiliser comme limite pour addgoal
* voir s'il ne faudrait pas maintenir une size à part pour les classes héritées de std::list (en l'état, l'implémentation GNU ne le fait pas et l'accès à size() se fait en O(n))
* construction incrémentale des Decomposition permettant d'inclure une étape de propagation pour renseigner l'heuristique des dates au plus tot : 
    * permettrait des opérateurs de variation moins aveugles
* voir si le l_max ne pourrait pas etre initialisé à partir du nombre total de date au plus tot (calculé par H1 dans lors de l'init)
    * très domaine dépendant, donc à tester
* construction progressive de la décomposition pour permettre une propagation mise à jour des dates au plus tot entre chaque goal intermédiaire à partir des états découverts
    * facile à faire dans yahsp
    * difficile dans DaE, car alors la chronopartition sera propre à chaque individu évalué
    * ne pourra etre utilisée qu'après par les opérateurs de mutation, donc on doit avoir une chronopartion par décomposition, mise à jour à chaque évaluation

----------------------------------

TODO BUT LATER

* Simplifier la classe atom, de manière à ne garder qu'un pointeur vers la structure de donnée correspondante dans le sous-solveur
* Supprimer toute la hierarchie utilisée pour l'affichage et utiliser une API d'affichage provenant du solveur
* Ajouter la possibilité d'avoir une liste de functor attachés à l'atome permettant de récupérer différentes propriétés (date au plus tot, landmarks, ...)
* Vincent pourra implémenter une vérification lors de la compréssion: vérifier qu'on ne rencontre pas deux fois le meme état dans la décomposition (auquel cas on veut supprimer les goals intermédiaires)

----------------------------------

DONE

* re-implementation of Jack's code, tested and debugged, now works
* database structure
* stat on average size of the decomposition
* suppress the maxtry-* parameters from the code, use the deterministic algorithm
* verify that every parametershave the correct default value
    * set the default pop size to 100 instead 20
        * remove the do_make_pop and do everything by hand so as to be sure of the default parameters and when the status is dumped
* compile DAE statically with all libraries
* add a loop for multi-start
* add a generic function to compute any quantile of the nodes distribution at the init phase

